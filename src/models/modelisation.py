#!/usr/bin/env python
# coding: utf-8

# Importation des librairies : 

import pandas as pd

from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from sklearn.ensemble import RandomForestRegressor

import os
import joblib
import sys

import dagshub
import mlflow
import mlflow.sklearn
from mlflow.models import infer_signature

# Importation de la librairie permettant la sauvegarde des fichiers de log : 
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from logging_script import setup_logging

# Initialisation du logger : 
logger = setup_logging()

# Connexion avec MLFlow pour le suivi des exp√©rimentations et l'enregistrement du mod√®le : 
dagshub.init(
    repo_owner="tiffany.dalmais",
    repo_name="OCT24_MLOPS_CO2",
    mlflow=True
)
mlflow.autolog()
with mlflow.start_run():
    logger.info("‚úÖ Entra√Ænement du mod√®le d√©marr√© avec succ√®s (modelisation.py).")

    # Importation de la configuration des chemins : 
    sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..")))
    import config

    # Chargement du nom du fichier de donn√©es pr√©trait√©es :
    processed_file_path = os.path.join(config.PROCESSED_DIR, "DF_Processed.csv")

    if not os.path.exists(processed_file_path):
        logger.error(f"‚ùå Le fichier {processed_file_path} n'existe pas.")
    else:
        try:
            df = pd.read_csv(processed_file_path)
            logger.info(f"‚öôÔ∏è Fichier .csv charg√© avec succ√®s : ({len(df)} lignes).")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du chargement du fichier .csv : {e}.")

    # S√©paration de X et y :
    try:
        X = df.drop(['Ewltp (g/km)', 'Cn', 'Year'], axis=1)
        y = df['Ewltp (g/km)']
        logger.info("‚úÖ S√©paration de X et y r√©ussie.")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la s√©paration des variables : {e}.")

    # Split train/test :
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    logger.info("‚úÖ Split train/test effectu√©.")

    # Normalisation :
    scaler = StandardScaler().fit(X_train)
    X_train_scaled = scaler.transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    logger.info("‚úÖ Donn√©es normalis√©es avec StandardScaler.")

    # Mod√®le final - RandomForestRegressor :
    model_final = RandomForestRegressor(bootstrap=False, max_features=0.75, min_samples_leaf=1,
                                        min_samples_split=9, n_estimators=100, random_state=42)
    model_final.fit(X_train_scaled, y_train)
    results_model_final = model_final.predict(X_test_scaled)
    logger.info("‚úÖ Mod√®le RandomForest entra√Æn√© avec succ√®s.")

    # Enregistrement du mod√®le dans MLFlow : 
    params = {
    "bootstrap": False,
    "max_features": 0.75,
    "min_samples_leaf": 1,
    "min_samples_split": 9,
    "n_estimators": 100,
    "random_state": 42
    }
    signature = infer_signature(X_test_scaled, results_model_final)

    # Affichage et enregistrement des metrics : 
    # Import des fonctions cr√©√©es dans le fichier metrics.py : 
    from src.utils.metrics import compute_metrics, save_metrics

    # Calcul et affichage des metrics : 
    metrics = compute_metrics(y_test, results_model_final)
    logger.info(f"üìä RMSE: {metrics['rmse']:.4f} | R¬≤: {metrics['r2']:.4f}")

    # Enregistrement des metrics : 
    os.makedirs(config.OUTPUTS_DIR, exist_ok=True)
    metrics_file = os.path.join(config.OUTPUTS_DIR, "metrics.json")
    save_metrics(metrics, metrics_file)
    logger.info(f"‚úÖ Fichier des m√©triques enregistr√© : {metrics_file}.")

    # Enregistrement des param√®tres et metrics : 
    mlflow.log_params(params)
    mlflow.log_metric("rmse", metrics["rmse"])
    mlflow.log_metric("r2", metrics["r2"])
    logger.info(f"‚úÖ Enregistrement des m√©triques et des param√®tres effectu√©.")
    
    # Enregistrement du mod√®le : 
    mlflow.sklearn.log_model(
        sk_model=model_final,
        artifact_path="sklearn-model",
        signature=signature,
        registered_model_name="RandomForest_Final",
    )
    logger.info("‚úÖ Mod√®le sauvegard√© sur MLFlow.")

    # Analyse des erreurs : 
    df_results_final = pd.DataFrame({'y_true': y_test, 'y_pred': results_model_final})
    df_results_final['error'] = abs(df_results_final['y_true'] - df_results_final['y_pred'])
    seuil = 20
    outliers = df_results_final[df_results_final['error'] > seuil]
    logger.info(f"üìå Affichage des √©carts de pr√©diction importants : \n {outliers.describe()}")

    # Cr√©ation de la variable contenant le nom du mod√®le : 
    model_filename = "RandomForest_Final.pkl"

    # Enregistrement du mod√®le : 
    # D√©finition du chemin :
    models_dir = config.MODELS_DIR

    # Cr√©ation du dossier s'il n'existe pas :
    os.makedirs(models_dir, exist_ok=True)

    # Construction du chemin complet vers le fichier dans le dossier "models" existant :
    model_path = os.path.join(models_dir, model_filename)

    # Enregistrement du mod√®le entra√Æn√© : 
    joblib.dump(model_final, model_path)
    logger.info(f"‚úÖ Mod√®le sauvegard√© localement : {model_path}.")