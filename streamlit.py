# Importation des librairies : 

import streamlit as st
import pandas as pd 
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error

import mlflow
from mlflow.models import infer_signature

import os
import json
import config
import dagshub

# Initialisation de DagsHub pour suivre les exp√©rimentations et les mod√®les : 

dagshub.init(
    repo_owner="tiffany.dalmais",
    repo_name="OCT24_MLOPS_CO2",
    mlflow=True
)

# Fonction pour charger et pr√©traiter le dataset
@st.cache_data
def load_and_preprocess_data():
    # Chargement du dataset :

    # Chargement du nom du fichier √† partir du fichier de m√©tadonn√©es :
    # Chemin vers le fichier "metadata.json" depuis le dossier initial : 
    metadata_path = os.path.join(config.METADATA_DIR, "metadata.json")

    # Lecture du fichier "metadata" :
    with open(metadata_path, "r") as f:
        metadata = json.load(f)

    # R√©cup√©ration du chemin du fichier "raw" tel qu'enregistr√© dans "metadata" : 
    processed_data_path = metadata.get("processed_data")

    # Chargement du fichier .csv :
    df = pd.read_csv(processed_data_path)
    
    # S√©lection des features (X) et de la target (y) : 
    baseline_features = ['M (kg)', 'Ec (cm3)', 'Ep (KW)', 'Erwltp (g/km)', 'Fc', 'Ft_Diesel', 'Ft_Essence']
    target = 'Ewltp (g/km)'

    X_baseline = df[baseline_features]
    y_baseline = df[target]
    
    # Split en train/test : 
    X_train, X_test, y_train, y_test = train_test_split(X_baseline, y_baseline, test_size=0.2, random_state=42)
    
    return df, X_train, X_test, y_train, y_test

# Charger le dataset
df, X_train, X_test, y_train, y_test = load_and_preprocess_data()

# Configuration de MLflow
mlflow.set_experiment("MLflow Streamlit")

# D√©finir les onglets
tabs = ["Exploration du Dataset", "Entra√Ænement des Mod√®les", "Historique des Runs", "Chargement des Mod√®les"]

# Cr√©ation des onglets
tab1, tab2, tab3, tab4 = st.tabs(tabs)

# Onglet 1 : Exploration du dataset
with tab1:
    st.header("üìä Exploration du Dataset")

    # Affichage d'un aper√ßu du dataset
    st.subheader("Aper√ßu du Dataset üìã")
    st.dataframe(df.head(10))  # Afficher les 10 premi√®res lignes

# Onglet 2 : Entra√Ænement des mod√®les
with tab2:
    st.header("üèãÔ∏è‚Äç‚ôÇÔ∏è Entra√Ænement des Mod√®les")

    # Affichage du mod√®le
    st.subheader("Choix du mod√®le üìã")

    # S√©lection du mod√®le
    model_choice = st.selectbox(
        "Choisissez un mod√®le de Machine Learning",
        ["R√©gression Lin√©aire", "KNN", "Random Forest"]
    )

    # Afficher le choix s√©lectionn√©
    st.write(f"üîç Mod√®le s√©lectionn√© : **{model_choice}**")

    # üìå Entra√Ænement et Logging MLflow
    if st.button("Entra√Æner le mod√®le"):
        
        with mlflow.start_run():
            
            # Mod√®le s√©lectionn√©
            if model_choice == "R√©gression Lin√©aire":
                model = LinearRegression()
            elif model_choice == "KNN":
                model = KNeighborsRegressor()
            elif model_choice == "Random Forest":
                model = RandomForestRegressor()
            
            # Entra√Ænement
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            # Calcul des m√©triques
            r2 = r2_score(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))

            # Log dans MLflow
            mlflow.log_metric("R2", r2)
            mlflow.log_metric("RMSE", rmse)

            # Ajouter un tag d'info
            mlflow.set_tag("Training Info", f"Mod√®le {model_choice} entra√Æn√© sur DF2023")

            # Enregistrer le mod√®le MLflow
            signature = infer_signature(X_train, model.predict(X_train))
            mlflow.sklearn.log_model(
                sk_model=model,
                artifact_path="test_model",
                signature=signature,
                input_example=X_train,
                registered_model_name="tracking-quickstart",
            )

            # Affichage des r√©sultats
            st.write(f"### üìä R√©sultats du Mod√®le : {model_choice}")
            st.write(f"**R¬≤ :** {r2:.4f}") #.4f sert √† avoir 4 chiffres apres la virgule
            st.write(f"**RMSE :** {rmse:.4f}") 

            # Affichage des valeurs r√©elles vs pr√©dictions
            result_df = pd.DataFrame({"Valeur R√©elle": y_test, "Pr√©diction": y_pred})
            st.dataframe(result_df.head(10))

# Onglet 3 : Historique des Runs
with tab3:
    st.header("üìú Historique des Runs MLflow")

    # Se connecter √† MLflow et r√©cup√©rer les runs tri√©s par date
    mlflow.set_experiment("MLflow Streamlit")
    runs = mlflow.search_runs(order_by=["start_time DESC"])  # Tri des runs du plus r√©cent au plus ancien

    if runs.empty:
        st.info("Aucun mod√®le enregistr√© pour l'instant. Lance un entra√Ænement !")
    else:
        # Extraire les informations clefs des runs
        df_runs = runs[["run_id", "metrics.R2", "metrics.RMSE", "start_time", "tags.mlflow.runName"]]
        df_runs.columns = ["Run ID", "R¬≤ Score", "RMSE", "Date", "Nom du mod√®le"]

        # S√©lectionner la derni√®re run par d√©faut
        latest_run_id = df_runs.iloc[0]["Run ID"]  # Premier √©l√©ment (le plus r√©cent)
        selected_run = st.selectbox("Affichage de la derni√®re Run :", list(df_runs["Nom du mod√®le"]), index=0)   

        # Afficher les d√©tails de la run s√©lectionn√©e
        run_details = df_runs[df_runs["Nom du mod√®le"] == selected_run]
        st.write(f"üìå **Nom du mod√®le** : {run_details['Nom du mod√®le'].values[0]}")
        st.write(f"üìÇ **Run ID** : {run_details['Run ID'].values[0]}")
        st.write(f"üìÖ **Date** : {run_details['Date'].values[0]}")
        st.write(f"üìä **R¬≤ Score** : {run_details['R¬≤ Score'].values[0]:.4f}")
        st.write(f"üìâ **RMSE** : {run_details['RMSE'].values[0]:.4f}")

# Onglet 4 : Chargement des mod√®les
with tab4:
    st.header("üöÄ Charger un Mod√®le MLflow et Pr√©dire")

    mlflow.set_experiment("MLflow Streamlit")
    runs = mlflow.search_runs(order_by=["start_time DESC"])  # Trier du plus r√©cent au plus ancien

    if runs.empty:
        st.info("Aucun mod√®le enregistr√© pour l'instant. Lance un entra√Ænement !")
    else:
        # Extraire les informations cl√©s des mod√®les enregistr√©s
        df_models = runs[["run_id", "tags.mlflow.runName"]]
        df_models.columns = ["Run ID", "Nom du Mod√®le"]

        # S√©lectionner un mod√®le via son nom
        selected_model_name = st.selectbox("üéØ Choisissez un Mod√®le :", df_models["Nom du Mod√®le"], index=0)
        selected_run_id = df_models[df_models["Nom du Mod√®le"] == selected_model_name]["Run ID"].values[0]  # R√©cup√©ration du Run ID correspondant

        # Charger le mod√®le MLflow s√©lectionn√©
        model_uri = f"runs:/{selected_run_id}/test_model"
        loaded_model = mlflow.pyfunc.load_model(model_uri)

        st.success(f"‚úÖ Mod√®le '{selected_model_name}' charg√© avec succ√®s !")

        # Formulaire pour entrer les caract√©ristiques du v√©hicule
        st.write("### üèéÔ∏è Entrez les caract√©ristiques du v√©hicule")
        with st.form("prediction_form"):
            col1, col2 = st.columns(2)
            with col1:
                m_kg = st.number_input("Masse du v√©hicule (kg)", min_value=500, max_value=3000, step=1)
                ec_cm3 = st.number_input("Cylindr√©e (cm¬≥)", min_value=500, max_value=6000, step=1)
            with col2:
                ep_kw = st.number_input("Puissance (kW)", min_value=20, max_value=500, step=1)
                erwltp = st.number_input("R√©duction d'√©missions WLTP (g/km)", min_value=0.0, max_value=3.5, step=0.01)

            fuel_consumption = st.number_input("Consommation de carburant (L/100km)", min_value=2.0, max_value=15.0, step=0.1)
            ft = st.selectbox("Type de carburant", ["Diesel", "Essence"])
            fuel_types = {"Diesel": [1, 0], "Essence": [0, 1]}
            ft_encoded = fuel_types[ft]

            # Construction de l'input (features utilis√©es lors de l'entra√Ænement)
            input_values = [m_kg, ec_cm3, ep_kw, erwltp, fuel_consumption] + ft_encoded
            input_data_df = pd.DataFrame([input_values], columns=['M (kg)', 'Ec (cm3)', 'Ep (KW)', 'Erwltp (g/km)', 'Fc', 'Ft_Diesel', 'Ft_Essence'])
            input_data_df = input_data_df.astype({
                "M (kg)": int,
                "Ec (cm3)": int,
                "Ep (KW)": int,
                "Erwltp (g/km)": float,
                "Fc": float,
                "Ft_Diesel": int,
                "Ft_Essence": int
                })

            submitted = st.form_submit_button("üîé Pr√©dire")

        # Faire la pr√©diction lorsque le formulaire est soumis
        if submitted:
            prediction = loaded_model.predict(input_data_df)
            st.success(f"üìä **Pr√©diction des √©missions de CO‚ÇÇ : {prediction[0]:.2f} g/km**")