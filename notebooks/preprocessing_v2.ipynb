{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f5bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des librairies :\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b063973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de la librairie permettant la sauvegarde des fichiers de log : \n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n",
    "from logging_script import setup_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb8f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de la configuration des chemins : \n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\", \"..\")))\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a21125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du logger : \n",
    "logger = setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf17f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Démarrage des logs :\n",
    "logger.info(\"✅ Script de preprocessing démarré avec succès (preprocessing.py).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af4fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du fichier .csv :\n",
    "raw_file_path = os.path.join(config.RAW_DIR, \"DF_Raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1ba01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(raw_file_path):\n",
    "    logger.error(f\"❌ Le fichier {raw_file_path} n'existe pas.\")\n",
    "else:\n",
    "    try:\n",
    "        df = pd.read_csv(raw_file_path)\n",
    "        logger.info(f\"⚙️ Fichier .csv chargé avec succès : ({len(df)} lignes).\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Erreur lors du chargement du fichier .csv : {e}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c804101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la présence des colonnes nécessaires\n",
    "    required_columns = ['Year', 'Mk', 'Cn', 'M (kg)', 'Ewltp (g/km)', 'Ft', 'Ec (cm3)', 'Ep (KW)', 'Erwltp (g/km)', 'Fc']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        logger.error(f\"❌ Colonne(s) manquante(s) dans le fichier .csv : {missing_columns}\")\n",
    "    else:\n",
    "        logger.info(\"✅ Toutes les colonnes nécessaires sont présentes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des doublons potentiels à travers les années. \n",
    "# On ne prend pas en compte la colonne \"Cn\" car de nombreuses variations d'orthographe existent pour un même modèle. \n",
    "subset_cols = [col for col in df.columns if col not in ['Cn', 'Year']]\n",
    "initial_count = len(df)\n",
    "df = df.drop_duplicates(subset=subset_cols)\n",
    "logger.info(f\"🔍 Suppression des doublons - Lignes restantes : {len(df)} (initialement {initial_count}).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe74e262",
   "metadata": {},
   "source": [
    "Vérification de la colonne \"Ft\" - Travail de catégorisation nécessaire :\n",
    "Passage en minuscules des catégories en doublon :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e4be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Ft' in df.columns:\n",
    "    df['Ft'] = df['Ft'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d01b0",
   "metadata": {},
   "source": [
    "Suppression des lignes contenant un \"unknown\" (majoritairement composées de NaN) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f251274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df = df[df['Ft'] != 'unknown']\n",
    "    logger.info(\"🎯 Transformation de 'Ft' terminée - Suppression des 'unknown'.\")\n",
    "else:\n",
    "    logger.warning(\"⚠️ Colonne 'Ft' absente, transformation non effectuée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342aef11",
   "metadata": {},
   "source": [
    "Rassemblement des variables :\n",
    "NB : Le dictionnaire peut être complété en cas de valeurs différentes dans le dataset utilisé : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16888440",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_fuel = {'petrol': 'Essence',\n",
    "            'hydrogen': 'Hydrogene',\n",
    "            'e85': 'Essence',\n",
    "            'lpg': 'GPL',\n",
    "            'ng': 'GPL',\n",
    "            'ng-biomethane': 'Bio-Carburant',\n",
    "            'diesel': 'Diesel',\n",
    "            'petrol/electric': 'Hybride',\n",
    "            'diesel/electric': 'Hybride',\n",
    "            'electric': 'Electrique'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317779e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ft'] = df['Ft'].replace(dico_fuel)\n",
    "logger.info(\"🔄 Remplacement des valeurs spécifiques de 'Ft' terminé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a2e64d",
   "metadata": {},
   "source": [
    "Mise de côté des modèles électriques (qui n'émettent pas directement de CO2) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5c33cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Ft'] != 'Electrique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8673888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passage en majuscules de la colonne \"Mk\" : \n",
    "if 'Mk' in df.columns:\n",
    "    df['Mk'] = df['Mk'].str.upper()\n",
    "    logger.info(\"📝 Les marques ont été converties en majuscules.\")\n",
    "else:\n",
    "    logger.warning(\"⚠️ Colonne 'Mk' absente, transformation non effectuée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec099b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Liste des marques les plus répandues en Europe : \n",
    "target_brands = ['CITROEN', 'FORD', 'FIAT', 'RENAULT', 'MERCEDES', 'BMW', 'VOLKSWAGEN', 'ALPINE', \n",
    "                 'INEOS', 'LAMBORGHINI', 'TOYOTA', 'JAGUAR', 'GREAT WALL MOTOR', 'CATERHAM', 'PEUGEOT', \n",
    "                 'MAN', 'OPEL', 'ALLIED VEHICLES', 'IVECO', 'MITSUBISHI', 'DS', 'MAZDA', 'SUZUKI', \n",
    "                 'SUBARU', 'HYUNDAI', \"AUDI\", \"NISSAN\", \"SKODA\", \"SEAT\", \"DACIA\", \"VOLVO\", \"KIA\",\n",
    "                 \"LAND ROVER\", \"MINI\", \"PORSCHE\", \"ALFA ROMEO\", \"SMART\", \"LANCIA\", \"JEEP\"\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a3b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les marques connues des chaînes de caractères : \n",
    "def extract_brand(value):\n",
    "    for brand in target_brands:\n",
    "        if brand in value:\n",
    "            return brand\n",
    "    return value\n",
    "df['Mk'] = df['Mk'].apply(extract_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b323d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction des fautes de frappe : \n",
    "dico_marque = {\n",
    "    'VW': 'VOLKSWAGEN',\n",
    "    '?KODA': 'SKODA',\n",
    "    'ŠKODA': 'SKODA',\n",
    "    'PSA AUTOMOBILES SA': 'PEUGEOT',\n",
    "    'FCA ITALY': 'FIAT',\n",
    "    'ALFA  ROMEO': 'ALFA ROMEO',\n",
    "    'LANDROVER': 'LAND ROVER'\n",
    "}\n",
    "df['Mk'] = df['Mk'].replace(dico_marque)\n",
    "logger.info(\"📝 Correction des marques terminée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338ebd38",
   "metadata": {},
   "source": [
    "Suppression des marques trop peu connues : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f21a7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "brands_to_delete = ['TRIPOD', 'API CZ', 'MOTO STAR', 'REMOLQUES RAMIREZ', 'AIR-BRAKES', \n",
    "                    'SIN MARCA', 'WAVECAMPER', 'CASELANI', 'PANDA']\n",
    "df = df[~df['Mk'].isin(brands_to_delete)]\n",
    "print(df[df['Mk'].isin(brands_to_delete)])\n",
    "logger.info(\"📝 Suppression des marques peu connues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60e8b0b",
   "metadata": {},
   "source": [
    "Suppression des occurences trop faibles : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746288c5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def filter_brands(df, col='Mk', threshold=5):\n",
    "    brands = df[col].tolist()\n",
    "    unique_brands = df[col].unique().tolist()\n",
    "    filtered_brands = [brand for brand in unique_brands if brands.count(brand) >= threshold]\n",
    "    return filtered_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95574df2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "filtered_brands = filter_brands(df, col='Mk', threshold=5)\n",
    "df = df[df['Mk'].isin(filtered_brands)]\n",
    "logger.info(\"📝 Suppression des occurences trop faibles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad0530c",
   "metadata": {},
   "source": [
    "Création d'une fonction pour détecter les valeurs aberrantes dans chaque colonne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f129c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def detect_outliers(df, target_col, group_cols=[\"Cn\", \"Ft\", \"Year\"]):\n",
    "    # Calcul de la moyenne par groupe :\n",
    "    stats = (\n",
    "        df.groupby(group_cols)\n",
    "          .agg(**{f'{target_col}_mean': (target_col, 'mean')})\n",
    "          .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Fusion du DataFrame initial avec les statistiques calculées :\n",
    "    df_merged = pd.merge(df, stats, on=group_cols, how=\"left\")\n",
    "    \n",
    "    # Calcul de l'écart absolu entre la valeur et la moyenne :\n",
    "    diff_col = f\"diff_{target_col}\"\n",
    "    df_merged[diff_col] = (df_merged[target_col] - df_merged[f\"{target_col}_mean\"]).abs()\n",
    "    \n",
    "    # Calcul des quartiles et de l'IQR :\n",
    "    q1 = df_merged[diff_col].quantile(0.25)\n",
    "    q3 = df_merged[diff_col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    # Calcul du seuil (Q3 + 1.5 * IQR) :\n",
    "    seuil = (q3 + 1.5 * iqr).round(1)\n",
    "\n",
    "    # Affichage du nombre d'outliers :\n",
    "    nb_outliers = len(df_merged[df_merged[diff_col] >= seuil])\n",
    "    logger.info(f'📌 Nombre de lignes dont la valeur de \"{target_col}\" dépasse le seuil de {seuil} : {nb_outliers}.')\n",
    "    \n",
    "    # Suppression des lignes présentant des outliers :\n",
    "    df_clean_no_outliers = df_merged[df_merged[diff_col] <= seuil]\n",
    "    logger.info(f\"🔄 Nombre de lignes après suppression des outliers : {len(df_clean_no_outliers)}.\")\n",
    "    \n",
    "    return df_clean_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f123f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des colonnes à filtrer successivement :\n",
    "columns_to_filter = ['Ewltp (g/km)', 'Fc', 'M (kg)', 'Ec (cm3)', 'Ep (KW)', 'Erwltp (g/km)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea409d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On part du DataFrame initial (que l'on copie pour ne pas altérer l'original) :\n",
    "df_temp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df248931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle sur chaque colonne pour appliquer le filtrage successif des outliers :\n",
    "for col in columns_to_filter:\n",
    "    df_temp = detect_outliers(df_temp, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbcd8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"✅ Après filtrage successif, le nombre de lignes restantes est de : {len(df_temp)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b84acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des valeurs aberrantes après traitement :\n",
    "df_clean_no_outliers_final = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfced63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colonnes ajoutées pour la détection de valeurs aberrantes afin d'éviter tout risque de fuite de données :\n",
    "df_clean_no_outliers_final = df_clean_no_outliers_final[['Mk', 'Cn', 'M (kg)', 'Ewltp (g/km)', 'Ft', 'Ec (cm3)', \n",
    "                                                         'Ep (KW)', 'Erwltp (g/km)', 'Year', 'Fc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921ad3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise de côté des modèles hybrides trop peu représentés : \n",
    "df_clean_no_outliers_final = df_clean_no_outliers_final[df_clean_no_outliers_final['Ft'] != 'Hybride']\n",
    "df_clean_no_outliers_final = df_clean_no_outliers_final[df_clean_no_outliers_final['Ft'] != 'Bio-Carburant']\n",
    "logger.info(\"🔄 Mise de côté des valeurs de 'Ft' trop peu représentées terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c45fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des variables catégorielles :\n",
    "# Encodage de \"Ft\" :\n",
    "df_clean_no_outliers_final = pd.get_dummies(df_clean_no_outliers_final, columns=['Ft'], prefix='Ft', drop_first=False)\n",
    "bool_cols = df_clean_no_outliers_final.select_dtypes(include=['bool']).columns\n",
    "df_clean_no_outliers_final[bool_cols] = df_clean_no_outliers_final[bool_cols].astype(int)\n",
    "logger.info(\"✅ Encodage de la variable 'Ft' terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage de \"Mk\" : \n",
    "df_clean_no_outliers_final = pd.get_dummies(df_clean_no_outliers_final, columns=['Mk'], prefix='Mk', drop_first=False)\n",
    "bool_cols = df_clean_no_outliers_final.select_dtypes(include=['bool']).columns\n",
    "df_clean_no_outliers_final[bool_cols] = df_clean_no_outliers_final[bool_cols].astype(int)\n",
    "logger.info(\"✅ Encodage de la variable 'Mk' terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7299cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement du fichier de données prétraitées : \n",
    "# Définir le chemin vers le dossier existant :\n",
    "processed_dir = config.PROCESSED_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cdf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du dossier s'il n'existe pas :\n",
    "try:\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    logger.info(\"🗂️ Dossier de sauvegarde des données prétraitées vérifié ou créé avec succès.\")\n",
    "except Exception as e:\n",
    "    logger.error(f'❌ Erreur lors de la création du dossier \"processed\" : {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93439a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de la variable contenant le nom du fichier .csv à exporter : \n",
    "output_filename = \"DF_Processed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa97fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction du chemin complet vers le fichier dans le dossier \"processed\" existant : \n",
    "output_filepath = os.path.join(processed_dir, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d87c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportation du DataFrame en .csv : \n",
    "if not df_clean_no_outliers_final.empty:\n",
    "    try:\n",
    "        df_clean_no_outliers_final.to_csv(output_filepath, index=False)\n",
    "        logger.info(f\"📁 Fichier .csv enregistré avec succès : {output_filepath}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Erreur lors de l'enregistrement du fichier .csv : {e}\")\n",
    "else:\n",
    "    logger.error(\"❌ Le DataFrame est vide. Aucune sauvegarde n'a été effectuée.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
